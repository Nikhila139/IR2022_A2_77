{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352c3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries such as nltk, pandas, numpy, etc...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690b4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing tokenizer, stop words, stemmer and lemmatizer from nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14b2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ba6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_process function that converts to lower case , removes punctuations and also does tokenization and lemmatization\n",
    "def pre_process(s):\n",
    "    s = s.lower()\n",
    "    l=len(string.punctuation)\n",
    "    s = s.translate(s.maketrans(string.punctuation,' '*l,''))\n",
    "    #s = re.sub('[^A-Za-z\\s\\n ]+', ' ',s)\n",
    "    \n",
    "    t = word_tokenize(s)\n",
    "    t = [lem.lemmatize(w) for w in t if w not in stopwords.words('english') and w.isalpha() and len(w)>1]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b8ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "doc={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c79a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st_aid.txt\n",
      "a-team\n",
      "abbott.txt\n",
      "aboutada.txt\n",
      "acetab1.txt\n",
      "aclamt.txt\n",
      "acne1.txt\n",
      "acronym.lis\n",
      "acronym.txt\n",
      "acronyms.txt\n",
      "adameve.hum\n",
      "adcopy.hum\n",
      "addrmeri.txt\n",
      "admin.txt\n",
      "adrian_e.faq\n",
      "ads.txt\n",
      "adt_miam.txt\n",
      "advrtize.txt\n",
      "aeonint.txt\n",
      "age.txt\n",
      "aggie.txt\n",
      "aids.txt\n",
      "airlines\n",
      "alabama.txt\n",
      "alcatax.txt\n",
      "alcohol.hum\n",
      "alflog.txt\n",
      "allfam.epi\n",
      "allusion\n",
      "all_grai\n",
      "amazing.epi\n",
      "ambrose.bie\n",
      "amchap2.txt\n",
      "analogy.hum\n",
      "aniherb.txt\n",
      "anime.cli\n",
      "anime.lif\n",
      "anim_lif.txt\n",
      "annoy.fascist\n",
      "anorexia.txt\n",
      "answers\n",
      "anthropo.stu\n",
      "antibiot.txt\n",
      "antimead.bev\n",
      "aphrodis.txt\n",
      "appbred.brd\n",
      "appetiz.rcp\n",
      "applepie.des\n",
      "apsaucke.des\n",
      "apsnet.txt\n",
      "arab.dic\n",
      "arcadian.txt\n",
      "argotdic.txt\n",
      "arnold.txt\n",
      "art-fart.hum\n",
      "arthriti.txt\n",
      "ateam.epi\n",
      "atherosc.txt\n",
      "atombomb.hum\n",
      "att.txt\n",
      "aussie.lng\n",
      "avengers.lis\n",
      "awespinh.sal\n",
      "ayurved.txt\n",
      "a_fish_c.apo\n",
      "a_tv_t-p.com\n",
      "b-2.jok\n",
      "b12.txt\n",
      "back1.txt\n",
      "bad\n",
      "bad-d\n",
      "bad.jok\n",
      "badday.hum\n",
      "bagelope.txt\n",
      "bakebred.txt\n",
      "baklava.des\n",
      "banana01.brd\n",
      "banana02.brd\n",
      "banana03.brd\n",
      "banana04.brd\n",
      "banana05.brd\n",
      "bank.rob\n",
      "barney.cn1\n",
      "barney.txt\n",
      "basehead.txt\n",
      "batrbred.txt\n",
      "bb\n",
      "bbc_vide.cat\n",
      "bbh_intv.txt\n",
      "bbq.txt\n",
      "beapimp.hum\n",
      "beauty.tm\n",
      "beave.hum\n",
      "beer-g\n",
      "beer-gui\n",
      "beer.gam\n",
      "beer.hum\n",
      "beer.txt\n",
      "beerdiag.txt\n",
      "beergame.hum\n",
      "beergame.txt\n",
      "beerjesus.hum\n",
      "beershrm.fis\n",
      "beershrp.fis\n",
      "beerwarn.txt\n",
      "beesherb.txt\n",
      "beginn.ers\n",
      "berryeto.bev\n",
      "bhang.fun\n",
      "bhb.ill\n",
      "bible.txt\n",
      "bigpic1.hum\n",
      "billcat.hum\n",
      "bimg.prn\n",
      "bingbong.hum\n",
      "bitchcar.hum\n",
      "bitnet.txt\n",
      "blackadd\n",
      "blackapp.hum\n",
      "blackhol.hum\n",
      "blake7.lis\n",
      "blaster.hum\n",
      "bless.bc\n",
      "blkbean.txt\n",
      "blkbnsrc.vgn\n",
      "blood.txt\n",
      "blooprs1.asc\n",
      "bmdn01.txt\n",
      "bnbeg2.4.txt\n",
      "bnbguide.txt\n",
      "bnb_quot.txt\n",
      "boarchil.txt\n",
      "boatmemo.jok\n",
      "boe.hum\n",
      "bond-2.txt\n",
      "boneles2.txt\n",
      "booknuti.txt\n",
      "booze.fun\n",
      "booze1.fun\n",
      "booze2.fun\n",
      "bored.txt\n",
      "boston.geog\n",
      "bozo_tv.leg\n",
      "brainect.hum\n",
      "brdpudd.des\n",
      "bread.rcp\n",
      "bread.rec\n",
      "bread.txt\n",
      "breadpud.des\n",
      "bredcake.des\n",
      "brewing\n",
      "browneco.hum\n",
      "brownie.rec\n",
      "brush1.txt\n",
      "btaco.txt\n",
      "btcisfre.hum\n",
      "btscke01.des\n",
      "btscke02.des\n",
      "btscke03.des\n",
      "btscke04.des\n",
      "btscke05.des\n",
      "buffwing.pol\n",
      "bugbreak.hum\n",
      "bugs.txt\n",
      "buldrwho.txt\n",
      "bunacald.fis\n",
      "burrito.mea\n",
      "butcher.txt\n",
      "butstcod.fis\n",
      "butwrong.hum\n",
      "buzzword.hum\n",
      "bw-phwan.hat\n",
      "bw-summe.hat\n",
      "bw.txt\n",
      "byfb.txt\n",
      "c0dez.txt\n",
      "cabbage.txt\n",
      "caesardr.sal\n",
      "cake.rec\n",
      "calamus.hrb\n",
      "calculus.txt\n",
      "calif.hum\n",
      "calvin.txt\n",
      "cancer.rat\n",
      "candy.txt\n",
      "candybar.fun\n",
      "capital.txt\n",
      "caramels.des\n",
      "carowner.txt\n",
      "cars.txt\n",
      "cartoon.law\n",
      "cartoon.laws\n",
      "cartoon_.txt\n",
      "cartoon_laws.txt\n",
      "cartwb.son\n",
      "cast.lis\n",
      "catballs.hum\n",
      "catin.hat\n",
      "catranch.hum\n",
      "catstory.txt\n",
      "cbmatic.hum\n",
      "cereal.txt\n",
      "cform2.txt\n",
      "cgs_lst.txt\n",
      "chainltr.txt\n",
      "change.hum\n",
      "charity.hum\n",
      "cheapfar.hum\n",
      "cheapin.la\n",
      "chickenheadbbs.txt\n",
      "chickens.jok\n",
      "chickens.txt\n",
      "childhoo.jok\n",
      "childrenbooks.txt\n",
      "chili.txt\n",
      "chinese.txt\n",
      "chinesec.hum\n",
      "choco-ch.ips\n",
      "christop.int\n",
      "chung.iv\n",
      "chunnel.txt\n",
      "church.sto\n",
      "clancy.txt\n",
      "classicm.hum\n",
      "climbing.let\n",
      "cmu.share\n",
      "co-car.jok\n",
      "cockney.alp\n",
      "coffee.faq\n",
      "coffee.txt\n",
      "coffeebeerwomen.txt\n",
      "cogdis.txt\n",
      "coke.fun\n",
      "coke.txt\n",
      "coke1\n",
      "cokeform.txt\n",
      "coke_fan.naz\n",
      "coladrik.fun\n",
      "coladrik.txt\n",
      "cold.fus\n",
      "coldfake.hum\n",
      "collected_quotes.txt\n",
      "college.hum\n",
      "college.sla\n",
      "college.txt\n",
      "comic_st.gui\n",
      "commutin.jok\n",
      "commword.hum\n",
      "computer.txt\n",
      "comrevi1.hum\n",
      "conan.txt\n",
      "confucius_say.txt\n",
      "consp.txt\n",
      "contract.moo\n",
      "cookberk\n",
      "cookbkly.how\n",
      "cookie.1\n",
      "cooking.fun\n",
      "cooking.jok\n",
      "coollngo2.txt\n",
      "cooplaws\n",
      "cops.txt\n",
      "corporat.txt\n",
      "court.quips\n",
      "cowexplo.hum\n",
      "coyote.txt\n",
      "crazy.txt\n",
      "critic.txt\n",
      "crzycred.lst\n",
      "cuchy.hum\n",
      "cucumber.jok\n",
      "cucumber.txt\n",
      "cuisine.txt\n",
      "cultmov.faq\n",
      "curiousgeorgie.txt\n",
      "curry.hrb\n",
      "curry.txt\n",
      "curse.txt\n",
      "cybrtrsh.txt\n",
      "d-ned.hum\n",
      "dalive\n",
      "damiana.hrb\n",
      "dandwine.bev\n",
      "dark.suc\n",
      "dead-r\n",
      "dead2.txt\n",
      "dead3.txt\n",
      "dead4.txt\n",
      "dead5.txt\n",
      "deadlysins.txt\n",
      "deathhem.txt\n",
      "deep.txt\n",
      "defectiv.hum\n",
      "desk.txt\n",
      "deterior.hum\n",
      "devils.jok\n",
      "diesmurf.txt\n",
      "diet.txt\n",
      "dieter.txt\n",
      "dingding.hum\n",
      "dining.out\n",
      "dirtword.txt\n",
      "disaster.hum\n",
      "disclmr.txt\n",
      "disclym.txt\n",
      "doc-says.txt\n",
      "docdict.txt\n",
      "docspeak.txt\n",
      "doggun.sto\n",
      "donut.txt\n",
      "dover.poem\n",
      "draxamus.txt\n",
      "drinker.txt\n",
      "drinking.tro\n",
      "drinkrul.jok\n",
      "drinks.gui\n",
      "drinks.txt\n",
      "drive.txt\n",
      "dromes.txt\n",
      "druggame.hum\n",
      "drugshum.hum\n",
      "drunk.txt\n",
      "dthought.txt\n",
      "dubltalk.jok\n",
      "dym\n",
      "eandb.drx\n",
      "earp\n",
      "eatme.txt\n",
      "econridl.fun\n",
      "egg-bred.txt\n",
      "egglentl.vgn\n",
      "eggroll1.mea\n",
      "electric.txt\n",
      "element.jok\n",
      "elephant.fun\n",
      "elevator.fun\n",
      "empeval.txt\n",
      "engineer.hum\n",
      "english\n",
      "english.txt\n",
      "engmuffn.txt\n",
      "engrhyme.txt\n",
      "enlightenment.txt\n",
      "enquire.hum\n",
      "epikarat.txt\n",
      "epiquest.txt\n",
      "episimp2.txt\n",
      "epitaph\n",
      "epi_.txt\n",
      "epi_bnb.txt\n",
      "epi_merm.txt\n",
      "epi_rns.txt\n",
      "epi_tton.txt\n",
      "eskimo.nel\n",
      "exam.50\n",
      "excuse.txt\n",
      "excuse30.txt\n",
      "excuses.txt\n",
      "exidy.txt\n",
      "exylic.txt\n",
      "facedeth.txt\n",
      "failure.txt\n",
      "fajitas.rcp\n",
      "farsi.phrase\n",
      "farsi.txt\n",
      "fartinfo.txt\n",
      "fartting.txt\n",
      "fascist.txt\n",
      "fbipizza.txt\n",
      "fearcola.hum\n",
      "fed.txt\n",
      "fegg!int.txt\n",
      "feggaqui.txt\n",
      "feggmagi.txt\n",
      "feista01.dip\n",
      "female.jok\n",
      "fiber.txt\n",
      "figure_1.txt\n",
      "filmgoof.txt\n",
      "films_gl.txt\n",
      "final-ex.txt\n",
      "finalexm.hum\n",
      "firecamp.txt\n",
      "fireplacein.txt\n",
      "firstaid.inf\n",
      "firstaid.txt\n",
      "fish.rec\n",
      "flattax.hum\n",
      "flowchrt\n",
      "flowchrt.txt\n",
      "flux_fix.txt\n",
      "focaccia.brd\n",
      "food\n",
      "foodtips\n",
      "footfun.hum\n",
      "forsooth.hum\n",
      "free-cof.fee\n",
      "freshman.hum\n",
      "freudonseuss.txt\n",
      "frogeye1.sal\n",
      "from.hum\n",
      "fuck!.txt\n",
      "fuckyou2.txt\n",
      "fudge.txt\n",
      "fusion.gal\n",
      "fusion.sup\n",
      "fwksfun.hum\n",
      "f_tang.txt\n",
      "gack!.txt\n",
      "gaiahuma\n",
      "gameshow.txt\n",
      "ganamembers.txt\n",
      "garlpast.vgn\n",
      "gas.txt\n",
      "gd_alf.txt\n",
      "gd_drwho.txt\n",
      "gd_flybd.txt\n",
      "gd_frasr.txt\n",
      "gd_gal.txt\n",
      "gd_guide.txt\n",
      "gd_hhead.txt\n",
      "gd_liqtv.txt\n",
      "gd_maxhd.txt\n",
      "gd_ol.txt\n",
      "gd_ql.txt\n",
      "gd_sgrnd.txt\n",
      "gd_tznew.txt\n",
      "german.aut\n",
      "get.drunk.cheap\n",
      "ghostfun.hum\n",
      "ghostsch.hum\n",
      "gingbeer.txt\n",
      "girlspeak.txt\n",
      "godmonth.txt\n",
      "goforth.hum\n",
      "gohome.hum\n",
      "goldwatr.txt\n",
      "golnar.txt\n",
      "good.txt\n",
      "gotukola.hrb\n",
      "gown.txt\n",
      "grail.txt\n",
      "grammar.jok\n",
      "greenchi.txt\n",
      "grommet.hum\n",
      "grospoem.txt\n",
      "growth.txt\n",
      "gumbo.txt\n",
      "hack\n",
      "hack7.txt\n",
      "hackingcracking.txt\n",
      "hackmorality.txt\n",
      "hacktest.txt\n",
      "hamburge.nam\n",
      "hammock.hum\n",
      "hangover.txt\n",
      "happyhack.txt\n",
      "harmful.hum\n",
      "hate.hum\n",
      "hbo_spec.rev\n",
      "headlnrs\n",
      "hecomes.jok\n",
      "hedgehog.txt\n",
      "height.txt\n",
      "hell.jok\n",
      "hell.txt\n",
      "herb!.hum\n",
      "hermsys.txt\n",
      "heroic.txt\n",
      "hi.tec\n",
      "hierarch.txt\n",
      "highland.epi\n",
      "hilbilly.wri\n",
      "history2.oop\n",
      "hitchcoc.app\n",
      "hitchcok.txt\n",
      "hitler.59\n",
      "hitler.txt\n",
      "hitlerap.txt\n",
      "homebrew.txt\n",
      "homermmm.txt\n",
      "hoonsrc.txt\n",
      "hoosier.txt\n",
      "hop.faq\n",
      "horflick.txt\n",
      "horoscop.jok\n",
      "horoscop.txt\n",
      "horoscope.txt\n",
      "hotel.txt\n",
      "hotnnot.hum\n",
      "hotpeper.txt\n",
      "how.bugs.breakd\n",
      "how2bgod.txt\n",
      "how2dotv.txt\n",
      "howlong.hum\n",
      "how_to_i.pro\n",
      "hstlrtxt.txt\n",
      "htswfren.txt\n",
      "hum2\n",
      "humatra.txt\n",
      "humatran.jok\n",
      "humor9.txt\n",
      "humpty.dumpty\n",
      "iced.tea\n",
      "icm.hum\n",
      "idaho.txt\n",
      "idr2.txt\n",
      "imbecile.txt\n",
      "imprrisk.hum\n",
      "impurmat.hum\n",
      "incarhel.hum\n",
      "indgrdn.txt\n",
      "initials.rid\n",
      "inlaws1.txt\n",
      "inquirer.txt\n",
      "ins1\n",
      "insanity.hum\n",
      "insect1.txt\n",
      "insult\n",
      "insult.lst\n",
      "insults1.txt\n",
      "insuranc.sty\n",
      "insure.hum\n",
      "interv.hum\n",
      "investi.hum\n",
      "iqtest\n",
      "iremember\n",
      "is_story.txt\n",
      "italoink.txt\n",
      "ivan.hum\n",
      "jac&tuu.hum\n",
      "jalapast.dip\n",
      "jambalay.pol\n",
      "japantv.txt\n",
      "japice.bev\n",
      "japrap.hum\n",
      "jargon.phd\n",
      "jason.fun\n",
      "jawgumbo.fis\n",
      "jawsalad.fis\n",
      "jayjay.txt\n",
      "jc-elvis.inf\n",
      "jeffie.heh\n",
      "jerky.rcp\n",
      "jimhood.txt\n",
      "johann\n",
      "jokeju07.txt\n",
      "jokes\n",
      "jokes.txt\n",
      "jokes1.txt\n",
      "jon.txt\n",
      "jrrt.riddle\n",
      "jungjuic.bev\n",
      "just2\n",
      "justify\n",
      "kaboom.hum\n",
      "kanalx.txt\n",
      "kashrut.txt\n",
      "kid2\n",
      "kid_diet.txt\n",
      "killer.hum\n",
      "killself.hum\n",
      "kilroy\n",
      "kilsmur.hum\n",
      "kloo.txt\n",
      "koans.txt\n",
      "labels.txt\n",
      "lampoon.jok\n",
      "languag.jok\n",
      "lansing.txt\n",
      "law.sch\n",
      "lawhunt.txt\n",
      "laws.txt\n",
      "lawskool.txt\n",
      "lawsuniv.hum\n",
      "lawyer.jok\n",
      "lawyers.txt\n",
      "lazarus.txt\n",
      "la_times.hun\n",
      "lbinter.hum\n",
      "leech.txt\n",
      "legal.hum\n",
      "let.go\n",
      "letgosh.txt\n",
      "letter.txt\n",
      "letterbx.txt\n",
      "letter_f.sch\n",
      "libraway.txt\n",
      "liceprof.sty\n",
      "lif&love.hum\n",
      "lifeimag.hum\n",
      "lifeinfo.hum\n",
      "lifeonledge.txt\n",
      "limerick.jok\n",
      "lines.jok\n",
      "lion.jok\n",
      "lion.txt\n",
      "lions.cat\n",
      "lipkovits.txt\n",
      "livnware.hum\n",
      "llamas.txt\n",
      "lll.hum\n",
      "llong.hum\n",
      "lobquad.hum\n",
      "looser.hum\n",
      "losers84.hum\n",
      "losers86.hum\n",
      "lost.txt\n",
      "lotsa.jok\n",
      "lozers\n",
      "lozerzon.hum\n",
      "lozeuser.hum\n",
      "lp-assoc.txt\n",
      "lucky.cha\n",
      "ludeinfo.hum\n",
      "ludeinfo.txt\n",
      "luggage.hum\n",
      "luvstory.txt\n",
      "luzerzo2.hum\n",
      "m0dzmen.hum\n",
      "macsfarm.old\n",
      "madhattr.jok\n",
      "madscrib.hum\n",
      "maecenas.hum\n",
      "mailfrag.hum\n",
      "makebeer.hum\n",
      "making_y.wel\n",
      "malechem.txt\n",
      "manager.txt\n",
      "manilla.hum\n",
      "manners.txt\n",
      "manspace.hum\n",
      "margos.txt\n",
      "marines.hum\n",
      "marriage.hum\n",
      "mash.hum\n",
      "math.1\n",
      "math.2\n",
      "math.far\n",
      "maxheadr\n",
      "mcd.txt\n",
      "mead.rcp\n",
      "meat2.txt\n",
      "meinkamp.hum\n",
      "mel.txt\n",
      "melodram.hum\n",
      "memo.hum\n",
      "memory.hum\n",
      "men&wome.txt\n",
      "mensroom.jok\n",
      "merry.txt\n",
      "miamadvi.hum\n",
      "miami.hum\n",
      "miamimth.txt\n",
      "middle.age\n",
      "mindvox\n",
      "minn.txt\n",
      "miranda.hum\n",
      "misc.1\n",
      "misery.hum\n",
      "missdish\n",
      "missheav.hum\n",
      "mitch.txt\n",
      "mlverb.hum\n",
      "modemwld.txt\n",
      "modest.hum\n",
      "modstup\n",
      "mog-history\n",
      "montoys.txt\n",
      "montpyth.hum\n",
      "moonshin\n",
      "moore.txt\n",
      "moose.txt\n",
      "moslem.txt\n",
      "mothers.txt\n",
      "motrbike.jok\n",
      "mov_rail.txt\n",
      "mowers.txt\n",
      "mr.rogers\n",
      "mrscienc.hum\n",
      "mrsfield\n",
      "msfields.txt\n",
      "msorrow\n",
      "mtm.hum\n",
      "mtv.asc\n",
      "mundane.v2\n",
      "murph.jok\n",
      "murphy.txt\n",
      "murphys.txt\n",
      "murphy_l.txt\n",
      "mutate.hum\n",
      "mydaywss.hum\n",
      "myheart.hum\n",
      "naivewiz.hum\n",
      "namaste.txt\n",
      "nameisreo.txt\n",
      "namm\n",
      "nasaglenn.txt\n",
      "necropls.txt\n",
      "netmask.txt\n",
      "netnews.10\n",
      "newcoke.txt\n",
      "newconst.hum\n",
      "newmex.hum\n",
      "news.hum\n",
      "nigel.1\n",
      "nigel.10\n",
      "nigel.2\n",
      "nigel.3\n",
      "nigel.4\n",
      "nigel.5\n",
      "nigel.6\n",
      "nigel.7\n",
      "nigel10.txt\n",
      "nihgel_8.9\n",
      "nintendo.jok\n",
      "normal.boy\n",
      "normalboy.txt\n",
      "normquot.txt\n",
      "nosuch_nasfic\n",
      "novel.hum\n",
      "nuke.hum\n",
      "nukeplay.hum\n",
      "nukewar.jok\n",
      "nukewar.txt\n",
      "nukwaste\n",
      "number\n",
      "number.killer\n",
      "number_k.ill\n",
      "nurds.hum\n",
      "nysucks.hum\n",
      "nzdrinks.txt\n",
      "o-ttalk.hum\n",
      "oakwood.txt\n",
      "oam-001.txt\n",
      "oam.nfo\n",
      "oasis\n",
      "oatbran.rec\n",
      "oculis.rcp\n",
      "odd_to.obs\n",
      "odearakk.hum\n",
      "office.txt\n",
      "ohandre.hum\n",
      "oilgluts.hum\n",
      "old.txt\n",
      "oldeng.hum\n",
      "oldtime.sng\n",
      "oldtime.txt\n",
      "oliver.txt\n",
      "oliver02.txt\n",
      "onan.txt\n",
      "one.par\n",
      "onetoone.hum\n",
      "onetotwo.hum\n",
      "ookpik.hum\n",
      "opinion.hum\n",
      "oracle.jok\n",
      "oranchic.pol\n",
      "orgfrost.bev\n",
      "ourfathr.txt\n",
      "outawork.erl\n",
      "outlimit.txt\n",
      "oxymoron.jok\n",
      "oxymoron.txt\n",
      "ozarks.hum\n",
      "p-law.hum\n",
      "packard.txt\n",
      "paddingurpapers.txt\n",
      "parabl.hum\n",
      "parades.hum\n",
      "parsnip.txt\n",
      "passage.hum\n",
      "passenge.sim\n",
      "pasta001.sal\n",
      "pat.txt\n",
      "pbcookie.des\n",
      "peanuts.txt\n",
      "peatchp.hum\n",
      "pecker.txt\n",
      "penisprt.txt\n",
      "penndtch\n",
      "pepper.txt\n",
      "pepsideg.txt\n",
      "petshop\n",
      "phony.hum\n",
      "phorse.hum\n",
      "phunatdi.ana\n",
      "phxbbs-m.txt\n",
      "pickup.lin\n",
      "pickup.txt\n",
      "pipespec.txt\n",
      "pizzawho.hum\n",
      "planeget.hum\n",
      "planetzero.txt\n",
      "poets.hum\n",
      "pol-corr.txt\n",
      "polemom.txt\n",
      "poli.tics\n",
      "policpig.hum\n",
      "poli_t.ics\n",
      "poll2res.hum\n",
      "polly.txt\n",
      "polly_.new\n",
      "poopie.txt\n",
      "popconc.hum\n",
      "popmach\n",
      "popmusi.hum\n",
      "post.nuc\n",
      "pot.txt\n",
      "potty.txt\n",
      "pournell.spo\n",
      "ppbeer.txt\n",
      "prac1.jok\n",
      "prac2.jok\n",
      "prac3.jok\n",
      "prac4.jok\n",
      "pracjoke.txt\n",
      "practica.txt\n",
      "prawblim.hum\n",
      "prayer.hum\n",
      "primes.jok\n",
      "princess.brd\n",
      "pro-fact.hum\n",
      "problem.txt\n",
      "progrs.gph\n",
      "proof.met\n",
      "prooftec.txt\n",
      "proposal.jok\n",
      "proudlyserve.txt\n",
      "prover.wisom\n",
      "prover_w.iso\n",
      "psalm.reagan\n",
      "psalm23.txt\n",
      "psalm_nixon\n",
      "psalm_re.aga\n",
      "psilaine.hum\n",
      "psycho.txt\n",
      "psych_pr.quo\n",
      "pukeprom.jok\n",
      "pun.txt\n",
      "pure.mat\n",
      "puzzle.spo\n",
      "puzzles.jok\n",
      "python_s.ong\n",
      "q.pun\n",
      "qttofu.vgn\n",
      "quack26.txt\n",
      "quantity.001\n",
      "quantum.jok\n",
      "quantum.phy\n",
      "quest.hum\n",
      "quick.jok\n",
      "quotes.bug\n",
      "quotes.jok\n",
      "quotes.txt\n",
      "quux_p.oem\n",
      "rabbit.txt\n",
      "racist.net\n",
      "radexposed.txt\n",
      "radiolaf.hum\n",
      "rapmastr.hum\n",
      "ratings.hum\n",
      "ratspit.hum\n",
      "raven.hum\n",
      "readme.bat\n",
      "reagan.hum\n",
      "realest.txt\n",
      "reasons.txt\n",
      "rec.por\n",
      "recepies.fun\n",
      "recip1.txt\n",
      "recipe.001\n",
      "recipe.002\n",
      "recipe.003\n",
      "recipe.004\n",
      "recipe.005\n",
      "recipe.006\n",
      "recipe.007\n",
      "recipe.008\n",
      "recipe.009\n",
      "recipe.010\n",
      "recipe.011\n",
      "recipe.012\n",
      "reconcil.hum\n",
      "record_.gap\n",
      "red-neck.jks\n",
      "reddwarf.sng\n",
      "reddye.hum\n",
      "rednecks.txt\n",
      "reeves.txt\n",
      "relative.ada\n",
      "religion.txt\n",
      "renored.txt\n",
      "renorthr.txt\n",
      "rent-a_cat\n",
      "rentals.hum\n",
      "repair.hum\n",
      "report.hum\n",
      "research.hum\n",
      "residncy.jok\n",
      "resolutn.txt\n",
      "resrch_p.hra\n",
      "resrch_phrase\n",
      "revolt.dj\n",
      "richbred.txt\n",
      "rinaldo.jok\n",
      "rinaldos.law\n",
      "rinaldos.txt\n",
      "ripoffpc.hum\n",
      "rns_bcl.txt\n",
      "rns_bwl.txt\n",
      "rns_ency.txt\n",
      "roach.asc\n",
      "roadpizz.txt\n",
      "robot.tes\n",
      "rocking.hum\n",
      "rockmus.hum\n",
      "sanshop.txt\n",
      "saveface.hum\n",
      "sawyer.txt\n",
      "scam.txt\n",
      "scratchy.txt\n",
      "seafood.txt\n",
      "seeds42.txt\n",
      "sf-zine.pub\n",
      "sfmovie.txt\n",
      "shameonu.hum\n",
      "shooters.txt\n",
      "shorties.jok\n",
      "shrink.news\n",
      "shuimai.txt\n",
      "shuttleb.hum\n",
      "signatur.jok\n",
      "sigs.txt\n",
      "silverclaws.txt\n",
      "simp.txt\n",
      "sinksub.txt\n",
      "skincat\n",
      "skippy.hum\n",
      "skippy.txt\n",
      "slogans.txt\n",
      "smackjok.hum\n",
      "smartass.txt\n",
      "smiley.txt\n",
      "smokers.txt\n",
      "smurf-03.txt\n",
      "smurfkil.hum\n",
      "smurfs.cc\n",
      "smurf_co.txt\n",
      "snapple.rum\n",
      "snipe.txt\n",
      "soccer.txt\n",
      "socecon.hum\n",
      "social.hum\n",
      "socks.drx\n",
      "solders.hum\n",
      "soleleer.hum\n",
      "solviets.hum\n",
      "some_hu.mor\n",
      "soporifi.abs\n",
      "sorority.gir\n",
      "spacever.hum\n",
      "speling.msk\n",
      "spelin_r.ifo\n",
      "spider.hum\n",
      "spoonlis.txt\n",
      "spydust.hum\n",
      "squids.gph\n",
      "staff.txt\n",
      "stagline.txt\n",
      "standard.hum\n",
      "startrek.txt\n",
      "stereo.txt\n",
      "steroid.txt\n",
      "stone.hum\n",
      "strattma.txt\n",
      "stressman.txt\n",
      "strine.txt\n",
      "strsdiet.txt\n",
      "studentb.txt\n",
      "stuf10.txt\n",
      "stuf11.txt\n",
      "st_silic.txt\n",
      "subb_lis.txt\n",
      "subrdead.hum\n",
      "suicide2.txt\n",
      "sungenu.hum\n",
      "supermar.rul\n",
      "swearfrn.hum\n",
      "sw_err.txt\n",
      "symbol.hum\n",
      "sysadmin.txt\n",
      "sysman.txt\n",
      "t-10.hum\n",
      "t-shirt.hum\n",
      "takenote.jok\n",
      "talebeat.hum\n",
      "talkbizr.txt\n",
      "taping.hum\n",
      "tarot.txt\n",
      "teens.txt\n",
      "teevee.hum\n",
      "telecom.q\n",
      "televisi.hum\n",
      "televisi.txt\n",
      "temphell.jok\n",
      "terbear.txt\n",
      "termpoem.txt\n",
      "terms.hum\n",
      "terrmcd'.hum\n",
      "terrnieg.hum\n",
      "test.hum\n",
      "test.jok\n",
      "test2.jok\n",
      "testchri.txt\n",
      "texbeef.txt\n",
      "texican.dic\n",
      "texican.lex\n",
      "textgrap.hum\n",
      "tfepisod.hum\n",
      "tfpoems.hum\n",
      "thecube.hum\n",
      "thermite.ana\n",
      "thesis.beh\n",
      "the_ant.txt\n",
      "the_math.hel\n",
      "thievco.txt\n",
      "three.txt\n",
      "throwawa.hum\n",
      "tickmoon.hum\n",
      "timetr.hum\n",
      "tnd.1\n",
      "top10.elf\n",
      "top10.txt\n",
      "top10st1.txt\n",
      "top10st2.txt\n",
      "topten.hum\n",
      "toxcwast.hum\n",
      "tpquote2.txt\n",
      "tpquotes.txt\n",
      "transp.txt\n",
      "trekfume.txt\n",
      "trekwes.hum\n",
      "tribble.hum\n",
      "trukdeth.txt\n",
      "truthlsd.hum\n",
      "truths.hum\n",
      "tshirts.jok\n",
      "tuflife.txt\n",
      "tuna.lab\n",
      "turbo.hum\n",
      "turing.shr\n",
      "turkey.fun\n",
      "twilight.txt\n",
      "twinkie.txt\n",
      "twinkies.jok\n",
      "twinpeak.txt\n",
      "t_zone.jok\n",
      "ukunderg.txt\n",
      "un.happy\n",
      "units.mea\n",
      "univ.odd\n",
      "unochili.txt\n",
      "urban.txt\n",
      "vaguemag.90s\n",
      "valujet.txt\n",
      "variety1.asc\n",
      "variety2.asc\n",
      "variety3.asc\n",
      "various.txt\n",
      "vegan.rcp\n",
      "vegkill.txt\n",
      "venganza.txt\n",
      "venison.txt\n",
      "voltron.hum\n",
      "vonthomp\n",
      "wacky.ani\n",
      "wagit.txt\n",
      "wagon.hum\n",
      "waitress.txt\n",
      "washroom.txt\n",
      "watchlip.hum\n",
      "wedding.hum\n",
      "weight.txt\n",
      "weights.hum\n",
      "welfare\n",
      "welfare.txt\n",
      "wetdream.hum\n",
      "whatbbs\n",
      "whatthe.hum\n",
      "whitbred.txt\n",
      "who.txt\n",
      "whoon1st.hum\n",
      "whoops.hum\n",
      "why-me.hum\n",
      "widows\n",
      "wimptest.txt\n",
      "wisconsi.txt\n",
      "wisdom\n",
      "wkrp.epi\n",
      "women.jok\n",
      "wonton.txt\n",
      "wood\n",
      "woodbine.txt\n",
      "woodbugs.txt\n",
      "woods.txt\n",
      "woodsmok.txt\n",
      "woolly_m.amm\n",
      "word.hum\n",
      "worldend.hum\n",
      "wrdnws1.txt\n",
      "wrdnws2.txt\n",
      "wrdnws3.txt\n",
      "wrdnws4.txt\n",
      "wrdnws5.txt\n",
      "wrdnws6.txt\n",
      "wrdnws7.txt\n",
      "wrdnws8.txt\n",
      "wrdnws9.txt\n",
      "x-drinks.txt\n",
      "xibovac.txt\n",
      "xtermin8.hum\n",
      "y.txt\n",
      "yjohncse.hum\n",
      "yogisays.txt\n",
      "yogurt.asc\n",
      "yuban.txt\n",
      "yuppies.hum\n",
      "zen.txt\n",
      "zgtoilet.txt\n",
      "zodiac.hum\n",
      "zucantom.sal\n",
      "zuccmush.sal\n"
     ]
    }
   ],
   "source": [
    "#processing and reading the files with encoding\n",
    "c=0\n",
    "for file in glob.glob(\"*\"):\n",
    "    c+=1\n",
    "    print(file)\n",
    "    doc[c]=file\n",
    "    with open(file, 'r', encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "        t=pre_process(text)\n",
    "        d[c]=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17d42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c967eb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "1133\n",
      "1133\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print(len(d))\n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd9adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbbdb5ad",
   "metadata": {},
   "source": [
    "# Jaccard Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3299d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating jaccard coefficient. taking intersection of doccument query and union of doccument and query\n",
    "def jaccard(t1,t2):\n",
    "    s1=set(t1)\n",
    "    s2=set(t2)\n",
    "    u=s1.union(s2)\n",
    "    i=s1.intersection(s2)\n",
    "    j=len(i)/len(u)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87aa73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the above jaccard function one after the other and finally sorting based on values\n",
    "def find_js(qt):\n",
    "    js=[]\n",
    "    for i in d:\n",
    "        js.append([jaccard(d[i],qt),i])\n",
    "    js.sort(key=lambda x:x[0])\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a8c792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Input Query:\n",
      "once upon a time.\n",
      "['upon', 'time']\n",
      "acetab1.txt\n",
      "aclamt.txt\n",
      "adameve.hum\n",
      "addrmeri.txt\n",
      "alcatax.txt\n"
     ]
    }
   ],
   "source": [
    "#taking input query from user and doing pre-processing and calling the function to find jaccard coefficient\n",
    "print(\"Enter Input Query:\")\n",
    "q=input()\n",
    "qt=pre_process(q)\n",
    "print(qt)\n",
    "js=find_js(qt)\n",
    "for i in range(5):\n",
    "    print(doc[js[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d563b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1e27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a905cb2",
   "metadata": {},
   "source": [
    "# TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b8f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57920\n"
     ]
    }
   ],
   "source": [
    "#find all unique words\n",
    "uw=[]\n",
    "for l in d:\n",
    "    l1=list(set(d[l]))\n",
    "    uw.extend(l1)\n",
    "    uw=list(set(uw))\n",
    "print(len(uw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d170fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the doccument frequency\n",
    "def doc_freq():\n",
    "    df={}\n",
    "    for i in d:\n",
    "        tl=list(set(d[i]))\n",
    "        for t in tl:\n",
    "            if t in df:\n",
    "                df[t]+=1\n",
    "            else:\n",
    "                df[t]=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31daf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57920\n"
     ]
    }
   ],
   "source": [
    "#printing the returned doccument frequency\n",
    "df=doc_freq()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a02d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the inverse document frequency.\n",
    "import math\n",
    "def inv_df():\n",
    "    idf={}\n",
    "    total_doc=len(d)\n",
    "    for t in df:\n",
    "        idf[t]=math.log(total_doc/df[t]+1)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ec50866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57920\n"
     ]
    }
   ],
   "source": [
    "idf=inv_df()\n",
    "print(len(idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91d7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9995efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function that is used to calculate the frequency.\n",
    "def freq():\n",
    "    f={}\n",
    "    for i in d:\n",
    "        f[i]={}\n",
    "        for t in d[i]:\n",
    "            if t in f[i]:\n",
    "                f[i][t]+=1\n",
    "            else:\n",
    "                f[i][t]=1\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc186b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n"
     ]
    }
   ],
   "source": [
    "f=freq()\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c76bf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abbott': 88, 'costello': 91, 'first': 27, 'well': 8, 'going': 1, 'new': 1, 'york': 1, 'yankee': 1, 'manager': 2, 'gave': 1, 'job': 1, 'coach': 3, 'long': 2, 'team': 5, 'look': 6, 'must': 1, 'know': 21, 'player': 3, 'certainly': 3, 'never': 1, 'met': 1, 'guy': 12, 'tell': 8, 'name': 22, 'playing': 8, 'oh': 3, 'seems': 1, 'give': 3, 'ball': 15, 'day': 2, 'peculiar': 1, 'mean': 2, 'funny': 1, 'strange': 1, 'pet': 1, 'like': 1, 'dizzy': 1, 'dean': 3, 'brother': 1, 'daffy': 2, 'french': 2, 'cousin': 1, 'goofe': 2, 'let': 1, 'see': 1, 'bag': 1, 'second': 13, 'third': 16, 'want': 6, 'find': 3, 'say': 3, 'yes': 8, 'gon': 3, 'na': 4, 'fellow': 3, 'baseman': 5, 'asking': 5, 'man': 1, 'go': 4, 'ahead': 2, 'pause': 12, 'got': 8, 'ta': 5, 'right': 3, 'pay': 1, 'every': 3, 'month': 1, 'get': 8, 'money': 2, 'dollar': 2, 'trying': 2, 'base': 16, 'sometimes': 1, 'wife': 2, 'come': 1, 'collect': 1, 'wrong': 1, 'wan': 1, 'sign': 4, 'one': 1, 'time': 4, 'change': 1, 'around': 1, 'changing': 1, 'nobody': 1, 'take': 1, 'easy': 1, 'buddy': 1, 'ok': 1, 'alright': 2, 'talking': 2, 'mentioned': 2, 'back': 2, 'would': 1, 'stay': 2, 'insist': 1, 'putting': 2, 'together': 3, 'outfield': 1, 'sure': 2, 'left': 4, 'fielder': 2, 'thought': 2, 'ask': 3, 'ya': 1, 'field': 3, 'infield': 1, 'center': 1, 'pitcher': 3, 'tomorrow': 6, 'today': 3, 'telling': 1, 'pitching': 4, 'listen': 1, 'break': 1, 'arm': 1, 'catcher': 4, 'couple': 1, 'behind': 1, 'plate': 1, 'fancy': 1, 'catching': 1, 'heavy': 2, 'hitter': 2, 'bunt': 2, 'good': 1, 'throw': 14, 'pick': 3, 'thing': 1, 'said': 4, 'even': 1, 'naturally': 11, 'somebody': 1, 'different': 1, 'saying': 1, 'whoever': 1, 'drop': 1, 'run': 1, 'triple': 1, 'play': 1, 'another': 1, 'hit': 1, 'fly': 1, 'darn': 2, 'shortstop': 1, 'end': 1, 'gfiles': 1}\n"
     ]
    }
   ],
   "source": [
    "print(f[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5739fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e63be312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function calculates term frequency using binary scheme and returns the value\n",
    "def bin_tf():\n",
    "    btf={}\n",
    "    for di in f:\n",
    "        btf[di]={}\n",
    "        for w in f[di]:\n",
    "            #if w in f[di]:\n",
    "            btf[di][w]=1\n",
    "            #else:\n",
    "                #btf[di][w]=0\n",
    "    return btf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "828add92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "{'aidcalendulacomfreyremediessickmedicine': 1, 'herbal': 1, 'first': 1, 'aid': 1, 'kit': 1, 'calendula': 1, 'ointment': 1, 'use': 1, 'minor': 1, 'cut': 1, 'graz': 1, 'red': 1, 'rash': 1, 'skin': 1, 'comfrey': 1, 'suitable': 1, 'bruise': 1, 'damage': 1, 'external': 1, 'blood': 1, 'vessel': 1, 'vein': 1, 'st': 1, 'johnswort': 1, 'oil': 1, 'beneficial': 1, 'itchy': 1, 'irritable': 1, 'psoriasis': 1, 'also': 1, 'good': 1, 'sunburn': 1, 'applied': 1, 'night': 1, 'liver': 1, 'mixture': 1, 'mild': 1, 'laxative': 1, 'property': 1, 'help': 1, 'digestion': 1, 'rich': 1, 'food': 1, 'take': 1, 'one': 1, 'teaspoon': 1, 'minute': 1, 'main': 1, 'meal': 1, 'parasite': 1, 'effective': 1, 'common': 1, 'internal': 1, 'infestation': 1, 'suspected': 1, 'abstain': 1, 'hour': 1, 'tablespoon': 1, 'little': 1, 'water': 1, 'repeat': 1, 'dose': 1, 'four': 1, 'another': 1, 'died': 1, 'able': 1, 'recommence': 1, 'eating': 1, 'last': 1, 'gasp': 1, 'may': 1, 'used': 1, 'wash': 1, 'nervine': 1, 'sedative': 1, 'drop': 1, 'daily': 1, 'empty': 1, 'stomach': 1, 'general': 1, 'trouble': 1, 'sleeping': 1, 'bed': 1, 'time': 1, 'astringent': 1, 'mix': 1, 'bleeding': 1, 'remedy': 1, 'occasional': 1, 'diarrhoea': 1, 'stricken': 1, 'run': 1, 'teaspoonful': 1, 'every': 1, 'two': 1, 'symptom': 1, 'subside': 1, 'follow': 1, 'echinacea': 1, 'goldenseal': 1, 'tincture': 1, 'similar': 1, 'effect': 1, 'anti': 1, 'biotic': 1, 'event': 1, 'serious': 1, 'infection': 1, 'etc': 1, 'half': 1, 'continue': 1, 'least': 1, 'week': 1, 'de': 1, 'externally': 1, 'antiseptic': 1, 'anaesthetic': 1, 'lotion': 1, 'previous': 1, 'long': 1, 'period': 1, 'taken': 1, 'internally': 1, 'month': 1, 'order': 1, 'boost': 1, 'overall': 1, 'effectiveness': 1, 'immune': 1, 'system': 1, 'important': 1, 'way': 1, 'intended': 1, 'substitute': 1, 'proper': 1, 'medical': 1, 'care': 1, 'attention': 1, 'persist': 1, 'please': 1, 'consult': 1, 'reputable': 1, 'health': 1, 'practitioner': 1}\n"
     ]
    }
   ],
   "source": [
    "btf=bin_tf()\n",
    "print(len(btf))\n",
    "print(btf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d855ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab618f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function calculates term frequency using raw count scheme and returns the value\n",
    "def rawcnt_tf():\n",
    "    rctf={}\n",
    "    for di in f:\n",
    "        rctf[di]={}\n",
    "        for w in f[di]:\n",
    "            rctf[di][w]=f[di][w]\n",
    "        \"\"\"for w in uw:\n",
    "            if w in f[di]:\n",
    "                rctf[di][w]=f[di][w]\n",
    "            else:\n",
    "                rctf[di][w]=0\"\"\"\n",
    "    return rctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e575d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "rctf=rawcnt_tf()\n",
    "print(len(rctf))\n",
    "print(len(rctf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96826e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56ae0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function calculates term frequency using term frequency scheme and returns the value\n",
    "def term_freq():\n",
    "    tf={}\n",
    "    for di in f:\n",
    "        tf[di]={}\n",
    "        s=sum(f[di].values())\n",
    "        for w in f[di]:\n",
    "            tf[di][w]=f[di][w]/s\n",
    "        \"\"\"for w in uw:\n",
    "            if w in f[di]:\n",
    "                tf[di][w]=f[di][w]/s\n",
    "            else:\n",
    "                tf[di][w]=0\"\"\"\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a88df5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "tf=term_freq()\n",
    "print(len(tf))\n",
    "print(len(tf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4731946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bcc32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function calculates term frequency using log normalization scheme and returns the value\n",
    "def log_tf():\n",
    "    ltf={}\n",
    "    for di in f:\n",
    "        ltf[di]={}\n",
    "        for w in f[di]:\n",
    "            ltf[di][w]=math.log(1+f[di][w])\n",
    "        \"\"\"for w in uw:\n",
    "            if w in f[di]:\n",
    "                ltf[di][w]=math.log(1+f[di][w])\n",
    "            else:\n",
    "                ltf[di][w]=0\"\"\"\n",
    "    return ltf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a6d8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "ltf=log_tf()\n",
    "print(len(ltf))\n",
    "print(len(ltf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6401de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21cb1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function calculates term frequency using double normalization scheme and returns the value\n",
    "def dn_tf():\n",
    "    dntf={}\n",
    "    for di in f:\n",
    "        dntf[di]={}\n",
    "        m=max(f[di].values())\n",
    "        for w in f[di]:\n",
    "            dntf[di][w]=0.5+0.5*(f[di][w]/m)\n",
    "        \"\"\"for w in uw:\n",
    "            if w in f[di]:\n",
    "                dntf[di][w]=0.5+0.5*(f[di][w]/m)\n",
    "            else:\n",
    "                dntf[di][w]=0\"\"\"\n",
    "    return dntf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecca9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "dntf=dn_tf()\n",
    "print(len(dntf))\n",
    "print(len(dntf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2672ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3ca1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=len(d)\n",
    "vl=len(uw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25068d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is the method for tf-idf which takes tf as parameters and multiplies with idf to get tf-idf\n",
    "def tf_idf(tf):\n",
    "    tfidf={}\n",
    "    for di in f:\n",
    "        tfidf[di]={}\n",
    "        for w in uw:\n",
    "            if w in tf[di]:\n",
    "                tf1=tf[di][w]\n",
    "            else:\n",
    "                tf1=0\n",
    "            idf1=idf[w]\n",
    "            tfidf[di][w]=tf1*idf1\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16036c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "57920\n"
     ]
    }
   ],
   "source": [
    "btfidf=tf_idf(btf)\n",
    "print(len(btfidf))\n",
    "print(len(btfidf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fc74529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "57920\n"
     ]
    }
   ],
   "source": [
    "rctfidf=tf_idf(rctf)\n",
    "print(len(rctfidf))\n",
    "print(len(rctfidf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1e7106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "57920\n"
     ]
    }
   ],
   "source": [
    "tfidf=tf_idf(tf)\n",
    "print(len(tfidf))\n",
    "print(len(tfidf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c918b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "57920\n"
     ]
    }
   ],
   "source": [
    "ltfidf=tf_idf(ltf)\n",
    "print(len(ltfidf))\n",
    "print(len(ltfidf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4aa7f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf1(tf):\n",
    "    tfidf={}\n",
    "    for di in f:\n",
    "        tfidf[di]={}\n",
    "        for w in uw:\n",
    "            if w in tf[di]:\n",
    "                tf1=tf[di][w]\n",
    "            else:\n",
    "                tf1=0.5\n",
    "            idf1=idf[w]\n",
    "            tfidf[di][w]=tf1*idf1\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89acd54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "57920\n"
     ]
    }
   ],
   "source": [
    "dntfidf=tf_idf1(dntf)\n",
    "print(len(dntfidf))\n",
    "print(len(dntfidf[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251e99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60e32366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following is the query method which gets the scores and finally sorts\n",
    "def query(qt,tfidf):\n",
    "    score={}\n",
    "    for d1 in d:\n",
    "        score[d1]=0\n",
    "        for t in qt:\n",
    "            score[d1]+=tfidf[d1][t]\n",
    "    dl=[]\n",
    "    dl1=sorted(range(1,len(score)+1), key=lambda i: score[i], reverse=True)[:6]\n",
    "    for i in dl1:\n",
    "        dl.append(doc[i])\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55ed5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Input Query:\n",
      "once upon a time\n",
      "['upon', 'time']\n",
      "\n",
      "binary \n",
      "adt_miam.txt allusion all_grai amazing.epi ambrose.bie ayurved.txt\n",
      "\n",
      "raw count \n",
      "mlverb.hum practica.txt barney.txt humor9.txt manners.txt xibovac.txt\n",
      "\n",
      "term frequency \n",
      "timetr.hum ookpik.hum sysman.txt yuppies.hum trukdeth.txt corporat.txt\n",
      "\n",
      "log norm \n",
      "barney.txt mindvox practica.txt quack26.txt humor9.txt jokes1.txt\n",
      "\n",
      "double norm \n",
      "ookpik.hum jokes1.txt trukdeth.txt ambrose.bie mindvox flux_fix.txt\n"
     ]
    }
   ],
   "source": [
    "#taking input query from the user and calculating all the five schemes.\n",
    "print(\"Enter Input Query:\")\n",
    "q=input()\n",
    "qt=pre_process(q)\n",
    "print(qt)\n",
    "\n",
    "#binary\n",
    "print(\"\\nbinary \")\n",
    "bd=query(qt,btfidf)\n",
    "print(*bd)\n",
    "\n",
    "#raw count\n",
    "print(\"\\nraw count \")\n",
    "rcd=query(qt,rctfidf)\n",
    "print(*rcd)\n",
    "\n",
    "#term frequency\n",
    "print(\"\\nterm frequency \")\n",
    "tfd=query(qt,tfidf)\n",
    "print(*tfd)\n",
    "\n",
    "#log norm\n",
    "print(\"\\nlog norm \")\n",
    "ld=query(qt,ltfidf)\n",
    "print(*ld)\n",
    "\n",
    "#double norm\n",
    "print(\"\\ndouble norm \")\n",
    "dnd=query(qt,dntfidf)\n",
    "print(*dnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4b015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1f07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a625fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236140a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61663f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d758aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e1f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1542682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a86f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a905b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747165b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee666e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accefe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b210ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4e17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8704eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255d3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05870deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3ff2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca81639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a933e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9302df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d4382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1bc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953d1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
